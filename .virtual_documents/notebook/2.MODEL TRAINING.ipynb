





# Basic Import 

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Modelling
from sklearn.metrics import precision_score,accuracy_score,recall_score,f1_score,roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from sklearn.neighbors import KNeighborsClassifier

# Ignore warnings
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)





df=pd.read_csv(r"C:\Users\HP\Desktop\projects\Adult_census_Income_Prediction\notebook\data\cleaned_Adult_dataset.csv")





df.head()


X=df.drop(['salary'],axis=1)
y=df['salary']


X


df['salary'].value_counts()


# Create Column Transformer with 3 types of transformers
num_features = X.select_dtypes(exclude="object").columns
cat_features = X.select_dtypes(include="object").columns

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.compose import ColumnTransformer

numeric_transformer = StandardScaler()
le_transformer = LabelEncoder()

X[num_features] = numeric_transformer.fit_transform(X[num_features])
for col in cat_features:
    X[col] = le_transformer.fit_transform(X[col])



print(num_features)
print(cat_features)


X.head()


y = y.map({' <=50K':0,' >50K':1})


X.shape,y.shape


pd.concat([X,y],axis=1).corr()





X = X.drop(["workclass","fnlwgt","education","occupation","race","country"],axis=1)
X


# separate dataset into train and test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
X_train.shape, X_test.shape





def evaluate_classification_model(true, predicted):
    """
    Calculate classification evaluation metrics.

    Parameters:
        true (array-like): True class labels.
        predicted (array-like): Predicted class labels.

    Returns:
        accuracy (float): Classification accuracy.
        precision (float): Precision score.
        recall (float): Recall score.
        f1 (float): F1-score.
    """
    accuracy = accuracy_score(true, predicted)
    precision = precision_score(true, predicted)
    recall = recall_score(true, predicted)
    f1 = f1_score(true, predicted)
    return accuracy, precision, recall, f1



# Define class weights for balancing classes
class_priors = y_train.value_counts(normalize=True).to_dict()

# Define class weights for balancing classes
class_weights = {0: class_priors[0], 1: class_priors[1]}

classification_models = {
    "Logistic Regression": LogisticRegression(class_weight=class_weights),
    "Random Forest Classifier": RandomForestClassifier(class_weight=class_weights),
    "K-Neighbors Classifier": KNeighborsClassifier(),
    "Decision Tree Classifier": DecisionTreeClassifier(class_weight=class_weights),
    "XGBoost Classifier": XGBClassifier(),
    "CatBoost Classifier": CatBoostClassifier(verbose=0),
    "AdaBoost Classifier": AdaBoostClassifier(),
    "Naive Bayes": GaussianNB(priors=list(class_weights.values()))
}

model_list = []
accuracy_list = []
precision_list = []
recall_list = []
f1_list = []

for model_name, model in classification_models.items():
    model.fit(X_train, y_train)  # Train model

    # Make predictions
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # Evaluate Train and Test dataset
    model_train_accuracy, model_train_precision, model_train_recall, model_train_f1 = evaluate_classification_model(y_train, y_train_pred)
    model_test_accuracy, model_test_precision, model_test_recall, model_test_f1 = evaluate_classification_model(y_test, y_test_pred)

    print(model_name)
    model_list.append(model_name)

    print('Model performance for Training set')
    print("- Accuracy Score: {:.4f}".format(model_train_accuracy))
    print("- Precision Score: {:.4f}".format(model_train_precision))
    print("- Recall Score: {:.4f}".format(model_train_recall))
    print("- F1 Score: {:.4f}".format(model_train_f1))

    print('----------------------------------')

    print('Model performance for Test set')
    print("- Accuracy Score: {:.4f}".format(model_test_accuracy))
    print("- Precision Score: {:.4f}".format(model_test_precision))
    print("- Recall Score: {:.4f}".format(model_test_recall))
    print("- F1 Score: {:.4f}".format(model_test_f1))

    accuracy_list.append(model_test_accuracy)
    precision_list.append(model_test_precision)
    recall_list.append(model_test_recall)
    f1_list.append(model_test_f1)

    print('=' * 35)
    print('\n')



pd.DataFrame(list(zip(model_list, accuracy_list, precision_list, recall_list, f1_list)), columns=["model_list", "accuracy_list", "precision_list", "recall_list", "f1_list"]).sort_values(by=["accuracy_list"],ascending=False)



